{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn.python.ops.rnn_cell import _linear\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "d=100\n",
    "N=60\n",
    "\n",
    "def flatten(tensor, keep):\n",
    "    fixed_shape = tensor.get_shape().as_list()\n",
    "    start = len(fixed_shape) - keep\n",
    "    left = reduce(mul, [fixed_shape[i] or tf.shape(tensor)[i] for i in range(start)])\n",
    "    out_shape = [left] + [fixed_shape[i] or tf.shape(tensor)[i] for i in range(start, len(fixed_shape))]\n",
    "    flat = tf.reshape(tensor, out_shape)\n",
    "    return flat\n",
    "\n",
    "def reconstruct(tensor, ref, keep):\n",
    "    ref_shape = ref.get_shape().as_list()\n",
    "    tensor_shape = tensor.get_shape().as_list()\n",
    "    ref_stop = len(ref_shape) - keep\n",
    "    tensor_start = len(tensor_shape) - keep\n",
    "    pre_shape = [ref_shape[i] or tf.shape(ref)[i] for i in range(ref_stop)]\n",
    "    keep_shape = [tensor_shape[i] or tf.shape(tensor)[i] for i in range(tensor_start, len(tensor_shape))]\n",
    "    # pre_shape = [tf.shape(ref)[i] for i in range(len(ref.get_shape().as_list()[:-keep]))]\n",
    "    # keep_shape = tensor.get_shape().as_list()[-keep:]\n",
    "    target_shape = pre_shape + keep_shape\n",
    "    out = tf.reshape(tensor, target_shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell=tf.nn.rnn_cell.BasicLSTMCell(d,state_is_tuple=True);\n",
    "q_mask = tf.placeholder('bool', [N, None], name='q_mask')\n",
    "x_mask = tf.placeholder('bool', [N, None, None], name='x_mask')\n",
    "xx=tf.Variable(np.ones([60, 1, 400, 200]),name='xx')\n",
    "qq=tf.Variable(np.ones([60, 30, 200]),name='qq')\n",
    "\n",
    "x_len = tf.reduce_sum(tf.cast(x_mask, 'int32'), 2)  # [N, M]\n",
    "q_len = tf.reduce_sum(tf.cast(q_mask, 'int32'), 1)  # [N]\n",
    "\n",
    "flat_inputs_q = flatten(qq, 2)  \n",
    "flat_len_q = None if q_len is None else tf.cast(flatten(q_len, 0), 'int64')\n",
    "\n",
    "flat_inputs_x = flatten(xx, 2)  \n",
    "flat_len_x = None if x_len is None else tf.cast(flatten(x_len, 0), 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"preprosessing\"):\n",
    "            (flat_fwu_outputs, flat_bwu_outputs), final_state =tf.nn.bidirectional_dynamic_rnn(cell, cell, flat_inputs_q, sequence_length=flat_len_q,dtype='float64',scope='lstm_query')\n",
    "            fw_u = reconstruct(flat_fwu_outputs, qq, 2)\n",
    "            bw_u = reconstruct(flat_bwu_outputs, qq, 2)\n",
    "        \n",
    "            u = tf.concat([fw_u, bw_u],2)\n",
    "        \n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            \n",
    "            (flat_fwh_outputs, flat_bwh_outputs), final_state =tf.nn.bidirectional_dynamic_rnn(cell, cell, flat_inputs_x, sequence_length=flat_len_x, dtype='float64', scope='lstm_context')\n",
    "            fw_h = reconstruct(flat_fwh_outputs, xx, 2)\n",
    "            bw_h = reconstruct(flat_bwh_outputs, xx, 2)\n",
    "            \n",
    "            h = tf.concat([fw_h, bw_h],3)  # [N, M, JX, 2d]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

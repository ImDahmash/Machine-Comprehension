{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from read_data import read_data, get_squad_data_filter, update_config\n",
    "from tensorflow.contrib.rnn.python.ops.rnn_cell import _linear\n",
    "import flag as fg\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = fg.main(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "batch_size = 100\n",
    "N = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.out_dir = os.path.join(config.out_base_dir, config.model_name, str(config.run_id).zfill(2))\n",
    "\n",
    "\n",
    "assert config.load or config.mode == 'train', \"config.load must be True if not training\"\n",
    "if not config.load and os.path.exists(config.out_dir):\n",
    "    shutil.rmtree(config.out_dir)\n",
    "\n",
    "config.save_dir = os.path.join(config.out_dir, \"save\")\n",
    "config.log_dir = os.path.join(config.out_dir, \"log\")\n",
    "config.eval_dir = os.path.join(config.out_dir, \"eval\")\n",
    "config.answer_dir = os.path.join(config.out_dir, \"answer\")\n",
    "if not os.path.exists(config.out_dir):\n",
    "    os.makedirs(config.out_dir)\n",
    "if not os.path.exists(config.save_dir):\n",
    "    os.mkdir(config.save_dir)\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.mkdir(config.log_dir)\n",
    "if not os.path.exists(config.answer_dir):\n",
    "    os.mkdir(config.answer_dir)\n",
    "if not os.path.exists(config.eval_dir):\n",
    "    os.mkdir(config.eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87507/87599 examples from train\n",
      "Loaded 10544/10570 examples from dev\n"
     ]
    }
   ],
   "source": [
    "data_filter = get_squad_data_filter(config)\n",
    "\n",
    "train_data = read_data(config, 'train', False, data_filter=data_filter)\n",
    "dev_data = read_data(config, 'dev', False, data_filter=data_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<read_data.DataSet at 0x7fe586320860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_config(config, [train_data, dev_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_dict = train_data.shared['lower_word2vec'] if config.lower_word else train_data.shared['word2vec']\n",
    "word2idx_dict = train_data.shared['word2idx']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2vec_dict = {word2idx_dict[word]: vec for word, vec in word2vec_dict.items() if word in word2idx_dict}\n",
    "emb_mat = np.array([idx2vec_dict[idx] if idx in idx2vec_dict\n",
    "                    else np.random.multivariate_normal(np.zeros(config.word_emb_size), np.eye(config.word_emb_size))\n",
    "                    for idx in range(config.word_vocab_size)])\n",
    "config.emb_mat = emb_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "pprint(config.__flags, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.get_variable('global_step', shape=[], dtype='int32', initializer=tf.constant_initializer(0), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 60\n",
      "M: 1\n",
      "JX: 866\n",
      "JQ: 30\n",
      "VW: 1224\n",
      "VC: 281\n",
      "W: 16\n",
      "d: 100\n"
     ]
    }
   ],
   "source": [
    "# Context and Ques Parameters\n",
    "N = config.batch_size\n",
    "M = config.max_num_sents\n",
    "JX = config.max_sent_size\n",
    "JQ = config.max_ques_size\n",
    "VW = config.word_vocab_size\n",
    "VC = config.char_vocab_size\n",
    "W = config.max_word_size\n",
    "d =  config.hidden_size\n",
    "dc = config.char_emb_size\n",
    "dw = config.word_emb_size\n",
    "dco = config.char_out_size\n",
    "\n",
    "print(\"N:\", N)\n",
    "print(\"M:\", M)\n",
    "print(\"JX:\", JX)\n",
    "print(\"JQ:\", JQ)\n",
    "print(\"VW:\", VW)\n",
    "print(\"VC:\", VC)\n",
    "print(\"W:\", W)\n",
    "print(\"d:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = train_data.shared['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = [list(itertools.chain(*X[0]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "\n",
    "x = tf.placeholder('int32', [N, None, None], name='x')\n",
    "cx = tf.placeholder('int32', [N, None, None, W], name='cx')\n",
    "x_mask = tf.placeholder('bool', [N, None, None], name='x_mask')\n",
    "q = tf.placeholder('int32', [N, None], name='q')\n",
    "cq = tf.placeholder('int32', [N, None, W], name='cq')\n",
    "q_mask = tf.placeholder('bool', [N, None], name='q_mask')\n",
    "y = tf.placeholder('bool', [N, None, None], name='y')\n",
    "y2 = tf.placeholder('bool', [N, None, None], name='y2')\n",
    "is_train = tf.placeholder('bool', [], name='is_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"emb\"):\n",
    "    if config.use_char_emb:\n",
    "        with tf.variable_scope(\"emb_var\"), tf.device(\"/cpu:0\"):\n",
    "            char_emb_mat = tf.get_variable(\"char_emb_mat\", shape=[VC, dc], dtype='float')\n",
    "    \n",
    "        with tf.variable_scope(\"char\"):\n",
    "            Acx = tf.nn.embedding_lookup(char_emb_mat, self.cx)  # [N, M, JX, W, dc]\n",
    "            Acq = tf.nn.embedding_lookup(char_emb_mat, self.cq)  # [N, JQ, W, dc]\n",
    "            Acx = tf.reshape(Acx, [-1, JX, W, dc])\n",
    "            Acq = tf.reshape(Acq, [-1, JQ, W, dc])\n",
    "            \n",
    "            filter_sizes = list(map(int, config.out_channel_dims.split(',')))\n",
    "            heights = list(map(int, config.filter_heights.split(',')))\n",
    "            assert sum(filter_sizes) == dco, (filter_sizes, dco)\n",
    "            \n",
    "            with tf.variable_scope(\"conv\"):\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.out_channel_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.filter_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
